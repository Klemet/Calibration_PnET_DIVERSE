Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/jupyter_cache/executors/utils.py", line 58, in single_nb_execution
    executenb(
  File "/usr/local/lib/python3.10/dist-packages/nbclient/client.py", line 1319, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "/usr/local/lib/python3.10/dist-packages/jupyter_core/utils/__init__.py", line 165, in wrapped
    return loop.run_until_complete(inner)
  File "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/usr/local/lib/python3.10/dist-packages/nbclient/client.py", line 709, in async_execute
    await self.async_execute_cell(
  File "/usr/local/lib/python3.10/dist-packages/nbclient/client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/usr/local/lib/python3.10/dist-packages/nbclient/client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
# First step : We're going to download the data from CanLEADv1 (which contain PAR values),
# and select only what is of interest to us (monthly values inside the polygon of the area
# we are simulating), then format the data into a dataframe we will use to create a GAM (Generalize Additive Model) afterwards.
# WARNING : The climate files from CanLEADv1 are temporarely downloaded one by one in the calibration folder, but are deleted when the operation
# is done, as they are very heavy (betwee 6-8 GB per file, and there are 4 files in total).
# The files are at https://crd-data-donnees-rdc.ec.gc.ca/CDAS/products/CanLEADv1/CanRCM4-EWEMBI-MBCn/r1_r1i1p1/, which
# corresponds to one of the 50 replicates of CanLEADv1 calibrated with the EWEMBI observational dataset.
# See https://crd-data-donnees-rdc.ec.gc.ca/CDAS/products/CanLEADv1 for readmes and documentation.
# WARNING : If a download fails, you can relaunch the cell. Downloads are done with Axel, which can re-start a download from where it was.
from functionsForCalibration import *
shapefile_Chapleau = "ReferencesAndData/ChapleauBoundariesClimate.shp"
canLEADv1_url = r"https://crd-data-donnees-rdc.ec.gc.ca/CDAS/products/CanLEADv1/CanRCM4-EWEMBI-MBCn/r1_r1i1p1/"

# If the file resulting from this cell already exists, we
# propose to the user not to run the cell - in order to not
# download the large file. Helps for re-runs of the notebook.
if os.path.exists("ReferencesAndData/dataInputForModel_CanLEADv1.csv"):
    confirmation = input("Do you want to run this cell? (yes/no): ")
    if confirmation.lower() == "yes" or confirmation.lower() == "y":
        # We start with the minimum temperature
        # We don't do it if the variable we need is already there
        if 'tasmin_monthly' not in locals():
            # We download the file
            file_name = "tasminAdjust_NAM-44i_CCCma-CanESM2_rcp85_r1_r1i1p1_CCCma-CanRCM4_r2_ECCC-MBCn-EWEMBI-1981-2010_day_19500101-21001231.nc"
            download_file(canLEADv1_url + file_name,
                          file_name)
            # We select only the data pertinent to our needs
            tasmin_ds = load_and_filter_by_polygon_canLEADv1(file_name, shapefile_Chapleau)
            # Transforming temperatures from kelvins to celcius
            tasmin_ds["tasminAdjust"] = kelvin_to_celsius(tasmin_ds["tasminAdjust"]) 
            # Resampling to monthly data
            tasmin_monthly = tasmin_ds.resample(time='1ME').min()
            # Free up memory
            del tasmin_ds
            os.remove(file_name)
        else:
            print("Variable tasmin_monthly exists, skipping download")
        
        # Now with the maximum temperature
        if 'tasmax_monthly' not in locals():
            # We download the file
            file_name = "tasmaxAdjust_NAM-44i_CCCma-CanESM2_rcp85_r1_r1i1p1_CCCma-CanRCM4_r2_ECCC-MBCn-EWEMBI-1981-2010_day_19500101-21001231.nc"
            download_file(canLEADv1_url + file_name,
                          file_name)
            # We select only the data pertinent to our needs
            tasmax_ds = load_and_filter_by_polygon_canLEADv1(file_name, shapefile_Chapleau)
            # Transforming temperatures from kelvins to celcius
            tasmax_ds["tasmaxAdjust"] = kelvin_to_celsius(tasmax_ds["tasmaxAdjust"])
            # Resampling to monthly data
            tasmax_monthly = tasmax_ds.resample(time='1ME').max()
            # Free up memory
            del tasmax_ds
            os.remove(file_name)
        else:
            print("Variable tasmax_monthly exists, skipping download")
        
        # Now with the precipitations
        if 'pr_monthly' not in locals():
            # We download the file
            file_name = "prAdjust_NAM-44i_CCCma-CanESM2_rcp85_r1_r1i1p1_CCCma-CanRCM4_r2_ECCC-MBCn-EWEMBI-1981-2010_day_19500101-21001231.nc"
            download_file(canLEADv1_url + file_name,
                          file_name)
            # We select only the data pertinent to our needs
            pr_ds = load_and_filter_by_polygon_canLEADv1(file_name, shapefile_Chapleau)
            # Transforming precipitations from their original unit - kg m-2 s-1 - into mm per day
            pr_ds["prAdjust"] = pr_ds["prAdjust"]*86400 # Going from seconds to days (86400 seconds in a day)
            # kg m-2 is already mm. So, we successfully went from kg m-2 s-1 to mm/day.
            # Resampling to monthly data
            pr_monthly = pr_ds.resample(time='1ME').sum()
            # Free up memory
            del pr_ds
            os.remove(file_name)
        else:
            print("Variable pr_monthly exists, skipping download")
        
        # We finish with PAR (downwelling shortwave radiation, or rsds in CanLEADv1)
        if 'rsds_monthly' not in locals():
            # We download the file
            file_name = "rsdsAdjust_NAM-44i_CCCma-CanESM2_rcp85_r1_r1i1p1_CCCma-CanRCM4_r2_ECCC-MBCn-EWEMBI-1981-2010_day_19500101-21001231.nc"
            download_file(canLEADv1_url + file_name,
                          file_name)
            # We select only the data pertinent to our needs
            rsds_ds = load_and_filter_by_polygon_canLEADv1(file_name, shapefile_Chapleau)
            # Transforming downwelling shortwave radiation from W/m2 to umol.m2/s-1
            # This one is a complex one. PnET user guide says that if the measure in W/m2 FOR SHORTWAVE (400-700nm), then just multiply it by 4.57.
            # However, if W/m2 measure is for TOTAL solar radiation, then we need another conversion factor to go to the shorwave + umol. See User Guide for more.
            # Here, we're normally in shortwave. I'll confirm by comparing the values to other measurement in PnET climate files.
            rsds_ds["rsdsAdjust"] = rsds_ds["rsdsAdjust"]*4.57
            # Resampling to monthly data
            rsds_monthly = rsds_ds.resample(time='1ME').mean()
            # Free up memory
            del rsds_ds
            os.remove(file_name)
        else:
            print("Variable rsds_monthly exists, skipping download")
        
        # We end up by preparign the data for making the GAM
        print("Preparing data for GAM...")
        # Create a DataFrame for each variable
        tasmin_df = tasmin_monthly["tasminAdjust"].to_dataframe().reset_index()
        tasmax_df = tasmax_monthly["tasmaxAdjust"].to_dataframe().reset_index()
        pr_df = pr_monthly["prAdjust"].to_dataframe().reset_index()
        rsds_df = rsds_monthly["rsdsAdjust"].to_dataframe().reset_index()
        
        # Merge DataFrames
        merged_df = pd.merge(tasmin_df, tasmax_df, on=['time', 'lat', 'lon'])
        merged_df = pd.merge(merged_df, pr_df, on=['time', 'lat', 'lon'])
        merged_df = pd.merge(merged_df, rsds_df, on=['time', 'lat', 'lon'])
        
        # Put time in time format
        merged_df['time'] = merged_df['time'].apply(convert_cftime_to_datetime)
        merged_df["time"] = pd.to_datetime(merged_df['time'], errors='coerce')
        
        # Extract month as a feature
        merged_df['month'] = merged_df['time'].dt.month
        
        # Drop rows with NaN values
        merged_df = merged_df.dropna()
        
        # Export the file
        merged_df.to_csv("ReferencesAndData/dataInputForModel_CanLEADv1.csv", sep=',', index=False, encoding='utf-8')
        print("Climate data for the GAM has been properly created and exported. See ReferencesAndData/dataInputForModel_CanLEADv1.csv")
    else:
        # Code to run if the user doesn't confirm
        print("Cell execution cancelled - dataInputForModel_CanLEADv1 was already there.")
------------------


[0;31m---------------------------------------------------------------------------[0m
[0;31mStdinNotImplementedError[0m                  Traceback (most recent call last)
Cell [0;32mIn[9], line 18[0m
[1;32m     14[0m [38;5;66;03m# If the file resulting from this cell already exists, we[39;00m
[1;32m     15[0m [38;5;66;03m# propose to the user not to run the cell - in order to not[39;00m
[1;32m     16[0m [38;5;66;03m# download the large file. Helps for re-runs of the notebook.[39;00m
[1;32m     17[0m [38;5;28;01mif[39;00m os[38;5;241m.[39mpath[38;5;241m.[39mexists([38;5;124m"[39m[38;5;124mReferencesAndData/dataInputForModel_CanLEADv1.csv[39m[38;5;124m"[39m):
[0;32m---> 18[0m     confirmation [38;5;241m=[39m [38;5;28;43minput[39;49m[43m([49m[38;5;124;43m"[39;49m[38;5;124;43mDo you want to run this cell? (yes/no): [39;49m[38;5;124;43m"[39;49m[43m)[49m
[1;32m     19[0m     [38;5;28;01mif[39;00m confirmation[38;5;241m.[39mlower() [38;5;241m==[39m [38;5;124m"[39m[38;5;124myes[39m[38;5;124m"[39m [38;5;129;01mor[39;00m confirmation[38;5;241m.[39mlower() [38;5;241m==[39m [38;5;124m"[39m[38;5;124my[39m[38;5;124m"[39m:
[1;32m     20[0m         [38;5;66;03m# We start with the minimum temperature[39;00m
[1;32m     21[0m         [38;5;66;03m# We don't do it if the variable we need is already there[39;00m
[1;32m     22[0m         [38;5;28;01mif[39;00m [38;5;124m'[39m[38;5;124mtasmin_monthly[39m[38;5;124m'[39m [38;5;129;01mnot[39;00m [38;5;129;01min[39;00m [38;5;28mlocals[39m():
[1;32m     23[0m             [38;5;66;03m# We download the file[39;00m

File [0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py:1281[0m, in [0;36mKernel.raw_input[0;34m(self, prompt)[0m
[1;32m   1279[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m [38;5;28mself[39m[38;5;241m.[39m_allow_stdin:
[1;32m   1280[0m     msg [38;5;241m=[39m [38;5;124m"[39m[38;5;124mraw_input was called, but this frontend does not support input requests.[39m[38;5;124m"[39m
[0;32m-> 1281[0m     [38;5;28;01mraise[39;00m StdinNotImplementedError(msg)
[1;32m   1282[0m [38;5;28;01mreturn[39;00m [38;5;28mself[39m[38;5;241m.[39m_input_request(
[1;32m   1283[0m     [38;5;28mstr[39m(prompt),
[1;32m   1284[0m     [38;5;28mself[39m[38;5;241m.[39m_parent_ident[[38;5;124m"[39m[38;5;124mshell[39m[38;5;124m"[39m],
[1;32m   1285[0m     [38;5;28mself[39m[38;5;241m.[39mget_parent([38;5;124m"[39m[38;5;124mshell[39m[38;5;124m"[39m),
[1;32m   1286[0m     password[38;5;241m=[39m[38;5;28;01mFalse[39;00m,
[1;32m   1287[0m )

[0;31mStdinNotImplementedError[0m: raw_input was called, but this frontend does not support input requests.

